\documentclass{beamer}
\usepackage{amsmath}

\title{GPU Implementation of Pb Edge Detection}
\author{Cristian Cucu \\ \texttt{cristian\_cucu@yahoo.com}}

%\usetheme{lucid}
\begin{document}
		
	
	\frame {
		\titlepage
	}
	\frame {
		\frametitle{Outline}
		\tableofcontents
	}
	\frame {
		\frametitle{Edge Detection - Introduction}
		Edge detection is a process in which the regions where sharp color transitions in images occur are found.
		Today we would like to show how a computation intensive, memory intensive edge detection algorithm can be implemented with CUDA.
	}
	\frame{
		\frametitle{Edge Detection - Important Categories of Methods \cite{xie} }
		\begin{itemize}
			\item Pioneering Methods
			\item Information Theory and Hand Crafted Features
			\item Learning Based Methods
			\item Deep Learning Based Methods
		\end{itemize}
	}
	\frame{
	    \frametitle{Pioneering Methods}
	    \framesubtitle{Sobel Detector}
	    	Edges in the vertical and horizontal direction can be computed my convoluting the image with a vertical or horizontal Sobel mask. The operators are as follows:
	    	
	    	\begin{itemize}
	    	\item Horizontal operator: \[
	    	M_x=
	    	\begin{bmatrix}
	    	1 & 0 & -1 \\
	    	2 & 0 & -2 \\
	    	1 & 0 & -1
	    	\end{bmatrix}
	    	\]
	    	\item Vertical operator:\[
	    	M_x=
	    	\begin{bmatrix}
	    	1 & 2 & 1 \\
	    	0 & 0 & 0 \\
	    	-1 & -2 & -1
	    	\end{bmatrix}
	    	\]
	    	\end{itemize}
    	}
    \frame{
    	\frametitle{Pioneering Methods}
    	\framesubtitle{Zero Crossing Method}
	    	Zero Crossing: The image is convoluted with a second-order derivative filter, for example the Laplacian of Gaussian. In the resulted image the zero values are marked as edges.
	    	
	    	\[
	    	LoG=
	    	\begin{bmatrix}
	    	0 & 1 & 1 & 2 & 2 & 2 & 1 & 1 & 0 \\
	    	1 & 2 & 4 & 5 & 5 & 5 & 4 & 2 & 1 \\
	    	1 & 4 & 5 & 3 & 0 & 3 & 5 & 4 & 1 \\
	    	2 & 5 & 3 & -12 & -24 & -12 & 3 & 5 & 2 \\
			2 & 5 & 0 &-24 & -40 & -24 & 0 & 5 & 2 \\
			2 & 5 & 3 & -12 & -24 & -12 & 3 & 5 & 2 \\
	    	1 & 4 & 5 & 3 & 0 & 3 & 5 & 4 & 1 \\
			1 & 2 & 4 & 5 & 5 & 5 & 4 & 2 & 1 \\
			0 & 1 & 1 & 2 & 2 & 2 & 1 & 1 & 0 \\	    	
	    	\end{bmatrix}
	    	\]
	    }
 	\frame{
		\frametitle {Information Theory and Hand Crafted Features \cite{konishi}}
		\framesubtitle {Statistical Edges}
		The methods calculates the multi-dimensional probability densities $P(\phi(I(x) | edge))$ and $P(\phi(I(x) | not-edge))$, where $\phi$ is a filter applied in the image I at the position x. A pixel in the image is on an edge when $\frac{P(\phi(I(x) | edge))}{P(\phi(I(x) | not-edge))} > T$ , where T is a suitably chosen threshold. The probability density functions are modelled as histograms.
	}
    \frame{
		\frametitle {Information Theory and Hand Crafted Features}
		\framesubtitle {Pb - Probability of Boundary - Edge Detector}
		For each point of an image and each orientation an edge value is computed as follows:
		\begin{itemize}
			\item A disc of radius R centered at the point is superimposed on the image
			\item The disc is divided into two half discs by a diameter with the chosen orientation
			\item For the image points in each half disc the histogram of intensities in the image (other features like texture, different color channel values are possible) are computed
			\item The gradient at the chosen point, with the given edge orientation, and disc radius is computed as the $\chi$-square distance between the two histograms computed
		\end{itemize}
	}
	\frame{
		\frametitle {Information Theory and Hand Crafted Features}
		\framesubtitle {Multiscale Pb - Part 1}
		A multiscale Pb detector for each orientation can be obtained with the following formula
		
		\[ mPb(x,y,\theta) = \sum_{s}^{} \sum_{i}^{}\alpha_{i,s} G_{i,\sigma(i,s)}(x,y,\theta) \]
		\begin{itemize}
			\item i represents the channel used (L, a, b or texture channel)
			\item s represents scales
			\item $G_{i,\sigma(i,s)}(x,y,\theta)$ represents the probability of boundary gradient in the image channel i, at the disc radius $\sigma(i,s)$, at the point (x,y) in image and with the orientation $\theta$
		\end{itemize}
	}

	\frame{
	\frametitle {Information Theory and Hand Crafted Features}
	\framesubtitle {Multiscale Pb - Part 2}
	In order to obtain orientation independent multiscale Pb edges the following is computed:
		\[ mPb(x,y) = \max\limits_{\theta} mPb(x,y,\theta)\]
	The edges are then thinned with a non-maximum suppression term.
	The parameters $\alpha_{i,s}$ are computed with a gradient ascent method on the training images.
		
	}	

	\frame{
	\frametitle {Information Theory and Hand Crafted Features}
	\framesubtitle {Global Pb - Part 1}
	To account for bigger context in the image a global component is added local component (mPb) in the gPb algorithm. This component is constructed as follows: 
	\begin{itemize}
		\item A square matrix W with dimension equal to the number of pixels in the image is defined as follows:
		\begin{itemize}
		 \item an influence radius r is chosen
		 \item when the distance between pixels i and j is smaller or equal r, : \[ W_{ij} = exp(-\max\limits_{p \in \bar{ij}} \frac{mPb(p)}{\rho})\], $\bar{ij}$ is the segment connecting i and j, 
		 \item when the distance between pixels i and j is equal than \[W_{ij} = 0\]
		 \end{itemize}
		\item A square matrix D as follows: \[ D_{ii} = \sum_{j} W_{ij}\]
		
	\end{itemize}	
	} 

	\frame{
	\frametitle {Information Theory and Hand Crafted Features}
	\framesubtitle {Global Pb - Part 2}
	\begin{itemize}
		\item A generalized eigenvalue problem is solved \[ (D - W) v = \lambda D v\]
		\item The eigenvectors $v_{n}$ associated with the n smallest non-trivial eigenvalues are taken. Each of them contains a value for each of image pixels. From each vector an image is recreated and gradient images with the gradient operator with orientation $\theta$ is computed. 
		\item The resulting global edges follow the formula: \[ sPb(x,y,\theta) = \sum_{k=1}^{n}\frac{1}{\sqrt{\lambda_{k}}} \nabla_{\theta} v_{k}(x,y) \]  
		
		
	\end{itemize}	
	} 

	\frame {
	\frametitle{CUDA - Introduction}
	\begin{itemize}
		\item CUDA is a framework developed by NVIDIA for programming with the GPU. 
		\item Supported graphic cards are the NVIDIA GPUs. 
		\item The programming language is an extension of C.
	\end{itemize}
	}

	\frame {
	\frametitle{CUDA - Programming model}
	\begin{itemize}
		\item Two main entities: host (CPU) and device (GPU).The host organizes data transfer to the GPU and starts the parallel operations on them.
		\item GPU can have thousands of processing units on which multiple threads are running.
		\item Data transfer from CPU to GPU is slow and must be minimized as much as possible.
	\end{itemize}
	}
	\frame {
	\frametitle{Allocate Host and Device Memory }
	\begin{itemize}
		\item Two main entities: host (CPU) and device (GPU).The host organizes data transfer to the GPU and starts the parallel operations on them.
		\item GPU can have thousands of processing units on which multiple threads are running.
		\item Data transfer from CPU to GPU is slow and must be minimized as much as possible.
		Today we would like to show how a computation intensive, memory intensive edge detection algorithm can be implemented with CUDA.
	\end{itemize}
}

	\frame {
	\frametitle{Implement a Kernel}
	\begin{itemize}
		\item Two main entities: host (CPU) and device (GPU).The host organizes data transfer to the GPU and starts the parallel operations on them.
		\item GPU can have thousands of processing units on which multiple threads are running.
		\item Data transfer from CPU to GPU is slow and must be minimized as much as possible.
		Today we would like to show how a computation intensive, memory intensive edge detection algorithm can be implemented with CUDA.
	\end{itemize}
}


	\frame {
	\frametitle{Pb - single thread version}
	Edge detection is a process in which the regions where sharp color transitions in images occur are found.
	Today we would like to show how a computation intensive, memory intensive edge detection algorithm can be implemented with CUDA.
	}

	\frame {
	\frametitle{Pb - CUDA version}
	Edge detection is a process in which the regions where sharp color transitions in images occur are found.
	Today we would like to show how a computation intensive, memory intensive edge detection algorithm can be implemented with CUDA.
}

	\begin{thebibliography}{9}		
		\bibitem{liu} 
		Yun Liu, Ming-Ming Cheng, Deng-Ping Fan, Le Zhang, Jia-Wang Bian, and Dacheng Tao, Fellow, IEEE
		\textit{Semantic Edge Detection with Diverse Deep Supervision} 
		IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018
		\bibitem{xie}
		Saining Xie, Zhuowen Tu, Holistically-Nested Edge Detection, arXiv 2015
		\bibitem{konishi}
		Scott Konishi, Alan L. Yuille, James M. Coughlan, and Song Chun Zhu
		\textit{Statistical Edge Detection: Learning and Evaluating Edge Cues}
		IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 25, No. 1, January 2003

	\end{thebibliography}

\end{document}




